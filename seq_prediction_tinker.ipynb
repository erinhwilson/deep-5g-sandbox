{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence prediction sandbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "        upstream_region_file,\n",
    "        data_mat_file, \n",
    "        sample2cond_file, \n",
    "        sample_file, \n",
    "        condition_file,\n",
    "        coded_meta_file\n",
    "        ):\n",
    "    '''\n",
    "    Wrapper function to load data from files into relavent objects\n",
    "    '''\n",
    "    # load upstream seq regions\n",
    "    seqs = u.load_promoter_seqs(upstream_region_file)\n",
    "    loc2seq = dict([(x,z) for (x,y,z) in seqs])\n",
    "    \n",
    "    # load TPM data\n",
    "    tpm_df = pd.read_csv(data_mat_file,sep='\\t').fillna('')\n",
    "\n",
    "    \n",
    "    # load mapping from sample to condition\n",
    "    with open(sample2cond_file,'r') as f:\n",
    "        sample2condition = dict(x.strip().split() for x in f.readlines())\n",
    "\n",
    "    \n",
    "    # load sample to include file\n",
    "    if sample_file:\n",
    "        with open(sample_file,'r') as f:\n",
    "            samples = list(x.strip() for x in f.readlines())\n",
    "    # if none provided, just use all the samples from the sample2condition dict\n",
    "    else: \n",
    "        samples = list(sample2condition.keys())\n",
    "\n",
    "        \n",
    "    # load the conditions to include file\n",
    "    if condition_file:\n",
    "        with open(condition_file,'r') as f:\n",
    "            conditions = list(x.strip() for x in f.readlines())\n",
    "    # if none provided, just use all the conditions\n",
    "    else:\n",
    "        conditions = list(set([sample2condition[x] for x in sample2condition]))\n",
    "\n",
    "    # load coded metadata file\n",
    "    meta_df = pd.read_csv(coded_meta_file,sep='\\t')\n",
    "    meta_df['sample'] = meta_df['#sample']+'_tpm'\n",
    "\n",
    "    return loc2seq, tpm_df, sample2condition, samples, conditions, meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_region_file = 'all_seq_info/all_loci_upstream_regions_w100_min20.fa'\n",
    "data_mat_file = 'data/extract_TPM_counts.tsv'\n",
    "sample2cond_file = 'data/sample2condition.txt'\n",
    "sample_file = None\n",
    "condition_file = 'data/conditions_to_include.txt'\n",
    "coded_meta_file = 'data/5G_exp_metadata_coded.tsv'\n",
    "COND_COLS = ['carbon_source','oxygen_level','nitrate_level','copper_level','lanthanum_level','growth_rate','growth_mode']\n",
    "\n",
    "\n",
    "loc2seq, tpm_df, sample2condition, samples, conditions, meta_df = load_data(\n",
    "    upstream_region_file,\n",
    "    data_mat_file, \n",
    "    sample2cond_file, \n",
    "    sample_file, \n",
    "    condition_file,\n",
    "    coded_meta_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_XY_dfs(tpm_df, meta_df):\n",
    "    # melt tpm df so every sample is in a row\n",
    "    tpm_melt = tpm_df[['locus_tag']+samples].melt(id_vars=['locus_tag'],var_name='sample',value_name='tpm')\n",
    "    tpm_melt['condition'] = tpm_melt['sample'].apply(lambda x: sample2condition[x])\n",
    "\n",
    "    # also add in upstream seq\n",
    "    tpm_melt['upstream_region'] = tpm_melt['locus_tag'].apply(lambda x: loc2seq[x])\n",
    "    \n",
    "    # get coded metadata conditions from meta_df\n",
    "    samp2cond_df = meta_df[['sample']+COND_COLS]\n",
    "\n",
    "    # merge back onto the tpm df\n",
    "    df = tpm_melt.merge(samp2cond_df,on='sample',how='left')\n",
    "    \n",
    "    # reformat full df\n",
    "    full_df = df[['locus_tag','upstream_region', 'sample','condition']+COND_COLS+['tpm']]\n",
    "    \n",
    "    # separate out just X (features) and Y (labels)\n",
    "    X = full_df[['locus_tag','upstream_region']+COND_COLS]\n",
    "    Y = full_df['tpm']\n",
    "    \n",
    "    return full_df,X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df, X, Y = format_XY_dfs(tpm_df,meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locus_tag</th>\n",
       "      <th>upstream_region</th>\n",
       "      <th>sample</th>\n",
       "      <th>condition</th>\n",
       "      <th>carbon_source</th>\n",
       "      <th>oxygen_level</th>\n",
       "      <th>nitrate_level</th>\n",
       "      <th>copper_level</th>\n",
       "      <th>lanthanum_level</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>growth_mode</th>\n",
       "      <th>tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EQU24_RS00005</td>\n",
       "      <td>CGCCGGTTTATGTCAATTATGCCGGCACTGATTTGATTGCTGTATA...</td>\n",
       "      <td>5GB1_ferm_Ack_QC_tpm</td>\n",
       "      <td>lowO2_slow_growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.933003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EQU24_RS00010</td>\n",
       "      <td>AACGCCGGTTTTACAGTTCATAAGCTATTGATAAATAAAATAAAAA...</td>\n",
       "      <td>5GB1_ferm_Ack_QC_tpm</td>\n",
       "      <td>lowO2_slow_growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.607784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EQU24_RS00015</td>\n",
       "      <td>ATCGCAGTCATTATTAAATGTGGAAGCAACAAAAAAACGAGCTTGT...</td>\n",
       "      <td>5GB1_ferm_Ack_QC_tpm</td>\n",
       "      <td>lowO2_slow_growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.415515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EQU24_RS00020</td>\n",
       "      <td>AACTTAATAACTATAAAATGTTCCACGTGGAACATGGTGAAATTAA...</td>\n",
       "      <td>5GB1_ferm_Ack_QC_tpm</td>\n",
       "      <td>lowO2_slow_growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.200081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EQU24_RS00025</td>\n",
       "      <td>CTTTGCCGAACACCCCGCACCTCCACGCGTCAACAACGAAATTTGA...</td>\n",
       "      <td>5GB1_ferm_Ack_QC_tpm</td>\n",
       "      <td>lowO2_slow_growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.522728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412869</th>\n",
       "      <td>EQU24_RS22135</td>\n",
       "      <td>CCCGGCCGGTTTGGTCTTGTACTGGGTGGTCAACAATACGCTGTCG...</td>\n",
       "      <td>5GB1C-JG15-N-BR2_tpm</td>\n",
       "      <td>NoLanthanum</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.508375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412870</th>\n",
       "      <td>EQU24_RS22140</td>\n",
       "      <td>GCCGCCCAGGGCACCTATCTTACAGTCCGAAGAGTATTAAAGTGTC...</td>\n",
       "      <td>5GB1C-JG15-N-BR2_tpm</td>\n",
       "      <td>NoLanthanum</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>130.851229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412871</th>\n",
       "      <td>EQU24_RS22145</td>\n",
       "      <td>AATATTGATGTTGTTGTTATGGCCCGAAAAGATGCACTCAATGCAT...</td>\n",
       "      <td>5GB1C-JG15-N-BR2_tpm</td>\n",
       "      <td>NoLanthanum</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66.415222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412872</th>\n",
       "      <td>EQU24_RS22150</td>\n",
       "      <td>AAGAACTCACGGCTTTCGTGCCAGAATGGCGACCAAAGGCGGCCGT...</td>\n",
       "      <td>5GB1C-JG15-N-BR2_tpm</td>\n",
       "      <td>NoLanthanum</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>164.123473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412873</th>\n",
       "      <td>EQU24_RS22155</td>\n",
       "      <td>ATCAGTGCCGGCATAATTGACATAAACCGGCGTTTATTCTATCATC...</td>\n",
       "      <td>5GB1C-JG15-N-BR2_tpm</td>\n",
       "      <td>NoLanthanum</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>301.751157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412874 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            locus_tag                                    upstream_region  \\\n",
       "0       EQU24_RS00005  CGCCGGTTTATGTCAATTATGCCGGCACTGATTTGATTGCTGTATA...   \n",
       "1       EQU24_RS00010  AACGCCGGTTTTACAGTTCATAAGCTATTGATAAATAAAATAAAAA...   \n",
       "2       EQU24_RS00015  ATCGCAGTCATTATTAAATGTGGAAGCAACAAAAAAACGAGCTTGT...   \n",
       "3       EQU24_RS00020  AACTTAATAACTATAAAATGTTCCACGTGGAACATGGTGAAATTAA...   \n",
       "4       EQU24_RS00025  CTTTGCCGAACACCCCGCACCTCCACGCGTCAACAACGAAATTTGA...   \n",
       "...               ...                                                ...   \n",
       "412869  EQU24_RS22135  CCCGGCCGGTTTGGTCTTGTACTGGGTGGTCAACAATACGCTGTCG...   \n",
       "412870  EQU24_RS22140  GCCGCCCAGGGCACCTATCTTACAGTCCGAAGAGTATTAAAGTGTC...   \n",
       "412871  EQU24_RS22145  AATATTGATGTTGTTGTTATGGCCCGAAAAGATGCACTCAATGCAT...   \n",
       "412872  EQU24_RS22150  AAGAACTCACGGCTTTCGTGCCAGAATGGCGACCAAAGGCGGCCGT...   \n",
       "412873  EQU24_RS22155  ATCAGTGCCGGCATAATTGACATAAACCGGCGTTTATTCTATCATC...   \n",
       "\n",
       "                      sample          condition  carbon_source  oxygen_level  \\\n",
       "0       5GB1_ferm_Ack_QC_tpm  lowO2_slow_growth              2             0   \n",
       "1       5GB1_ferm_Ack_QC_tpm  lowO2_slow_growth              2             0   \n",
       "2       5GB1_ferm_Ack_QC_tpm  lowO2_slow_growth              2             0   \n",
       "3       5GB1_ferm_Ack_QC_tpm  lowO2_slow_growth              2             0   \n",
       "4       5GB1_ferm_Ack_QC_tpm  lowO2_slow_growth              2             0   \n",
       "...                      ...                ...            ...           ...   \n",
       "412869  5GB1C-JG15-N-BR2_tpm        NoLanthanum              2             1   \n",
       "412870  5GB1C-JG15-N-BR2_tpm        NoLanthanum              2             1   \n",
       "412871  5GB1C-JG15-N-BR2_tpm        NoLanthanum              2             1   \n",
       "412872  5GB1C-JG15-N-BR2_tpm        NoLanthanum              2             1   \n",
       "412873  5GB1C-JG15-N-BR2_tpm        NoLanthanum              2             1   \n",
       "\n",
       "        nitrate_level  copper_level  lanthanum_level  growth_rate  \\\n",
       "0                   0             3                0            0   \n",
       "1                   0             3                0            0   \n",
       "2                   0             3                0            0   \n",
       "3                   0             3                0            0   \n",
       "4                   0             3                0            0   \n",
       "...               ...           ...              ...          ...   \n",
       "412869              0             3                0            2   \n",
       "412870              0             3                0            2   \n",
       "412871              0             3                0            2   \n",
       "412872              0             3                0            2   \n",
       "412873              0             3                0            2   \n",
       "\n",
       "        growth_mode         tpm  \n",
       "0                 0    2.933003  \n",
       "1                 0    1.607784  \n",
       "2                 0    1.415515  \n",
       "3                 0    3.200081  \n",
       "4                 0    1.522728  \n",
       "...             ...         ...  \n",
       "412869            1   24.508375  \n",
       "412870            1  130.851229  \n",
       "412871            1   66.415222  \n",
       "412872            1  164.123473  \n",
       "412873            1  301.751157  \n",
       "\n",
       "[412874 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locus_tag</th>\n",
       "      <th>upstream_region</th>\n",
       "      <th>carbon_source</th>\n",
       "      <th>oxygen_level</th>\n",
       "      <th>nitrate_level</th>\n",
       "      <th>copper_level</th>\n",
       "      <th>lanthanum_level</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>growth_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EQU24_RS00005</td>\n",
       "      <td>CGCCGGTTTATGTCAATTATGCCGGCACTGATTTGATTGCTGTATA...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EQU24_RS00010</td>\n",
       "      <td>AACGCCGGTTTTACAGTTCATAAGCTATTGATAAATAAAATAAAAA...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EQU24_RS00015</td>\n",
       "      <td>ATCGCAGTCATTATTAAATGTGGAAGCAACAAAAAAACGAGCTTGT...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EQU24_RS00020</td>\n",
       "      <td>AACTTAATAACTATAAAATGTTCCACGTGGAACATGGTGAAATTAA...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EQU24_RS00025</td>\n",
       "      <td>CTTTGCCGAACACCCCGCACCTCCACGCGTCAACAACGAAATTTGA...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412869</th>\n",
       "      <td>EQU24_RS22135</td>\n",
       "      <td>CCCGGCCGGTTTGGTCTTGTACTGGGTGGTCAACAATACGCTGTCG...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412870</th>\n",
       "      <td>EQU24_RS22140</td>\n",
       "      <td>GCCGCCCAGGGCACCTATCTTACAGTCCGAAGAGTATTAAAGTGTC...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412871</th>\n",
       "      <td>EQU24_RS22145</td>\n",
       "      <td>AATATTGATGTTGTTGTTATGGCCCGAAAAGATGCACTCAATGCAT...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412872</th>\n",
       "      <td>EQU24_RS22150</td>\n",
       "      <td>AAGAACTCACGGCTTTCGTGCCAGAATGGCGACCAAAGGCGGCCGT...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412873</th>\n",
       "      <td>EQU24_RS22155</td>\n",
       "      <td>ATCAGTGCCGGCATAATTGACATAAACCGGCGTTTATTCTATCATC...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412874 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            locus_tag                                    upstream_region  \\\n",
       "0       EQU24_RS00005  CGCCGGTTTATGTCAATTATGCCGGCACTGATTTGATTGCTGTATA...   \n",
       "1       EQU24_RS00010  AACGCCGGTTTTACAGTTCATAAGCTATTGATAAATAAAATAAAAA...   \n",
       "2       EQU24_RS00015  ATCGCAGTCATTATTAAATGTGGAAGCAACAAAAAAACGAGCTTGT...   \n",
       "3       EQU24_RS00020  AACTTAATAACTATAAAATGTTCCACGTGGAACATGGTGAAATTAA...   \n",
       "4       EQU24_RS00025  CTTTGCCGAACACCCCGCACCTCCACGCGTCAACAACGAAATTTGA...   \n",
       "...               ...                                                ...   \n",
       "412869  EQU24_RS22135  CCCGGCCGGTTTGGTCTTGTACTGGGTGGTCAACAATACGCTGTCG...   \n",
       "412870  EQU24_RS22140  GCCGCCCAGGGCACCTATCTTACAGTCCGAAGAGTATTAAAGTGTC...   \n",
       "412871  EQU24_RS22145  AATATTGATGTTGTTGTTATGGCCCGAAAAGATGCACTCAATGCAT...   \n",
       "412872  EQU24_RS22150  AAGAACTCACGGCTTTCGTGCCAGAATGGCGACCAAAGGCGGCCGT...   \n",
       "412873  EQU24_RS22155  ATCAGTGCCGGCATAATTGACATAAACCGGCGTTTATTCTATCATC...   \n",
       "\n",
       "        carbon_source  oxygen_level  nitrate_level  copper_level  \\\n",
       "0                   2             0              0             3   \n",
       "1                   2             0              0             3   \n",
       "2                   2             0              0             3   \n",
       "3                   2             0              0             3   \n",
       "4                   2             0              0             3   \n",
       "...               ...           ...            ...           ...   \n",
       "412869              2             1              0             3   \n",
       "412870              2             1              0             3   \n",
       "412871              2             1              0             3   \n",
       "412872              2             1              0             3   \n",
       "412873              2             1              0             3   \n",
       "\n",
       "        lanthanum_level  growth_rate  growth_mode  \n",
       "0                     0            0            0  \n",
       "1                     0            0            0  \n",
       "2                     0            0            0  \n",
       "3                     0            0            0  \n",
       "4                     0            0            0  \n",
       "...                 ...          ...          ...  \n",
       "412869                0            2            1  \n",
       "412870                0            2            1  \n",
       "412871                0            2            1  \n",
       "412872                0            2            1  \n",
       "412873                0            2            1  \n",
       "\n",
       "[412874 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           2.933003\n",
       "1           1.607784\n",
       "2           1.415515\n",
       "3           3.200081\n",
       "4           1.522728\n",
       "             ...    \n",
       "412869     24.508375\n",
       "412870    130.851229\n",
       "412871     66.415222\n",
       "412872    164.123473\n",
       "412873    301.751157\n",
       "Name: tpm, Length: 412874, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "    #print(\"one hot encoding...\")\n",
    "    \n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'A':[1.0,0.0,0.0,0.0],\n",
    "             'C':[0.0,1.0,0.0,0.0],\n",
    "             'G':[0.0,0.0,1.0,0.0],\n",
    "             'T':[0.0,0.0,0.0,1.0],\n",
    "             'N':[0.0,0.0,0.0,0.0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    #vec=torch.tensor([nuc_d[x] for x in seq])\n",
    "    vec=np.array([nuc_d[x] for x in seq]).flatten()\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('AAAAAA', 10.0),\n",
    "    ('ATAAAA', 9.0),\n",
    "    ('AAAACA', 9.8),\n",
    "    ('CCAACA', 8.0),\n",
    "    ('CCCCCC', 7.0),\n",
    "    ('CGGACC', 6.8),\n",
    "    ('CCCGCC', 6.7),\n",
    "    ('GGGACG', 6.2),\n",
    "    ('CGGGCG', 5.0),\n",
    "    ('GGGGGG', 4.0),\n",
    "    ('GCCGGT', 4.1),\n",
    "    ('TGGTGT', 3.0),\n",
    "    ('CGGTTG', 3.4),\n",
    "    ('TTGTGT', 2.0),\n",
    "    ('TTTTTT', 1.0),\n",
    "    ('TAATTA', 5.1),\n",
    "    ('GAGTGA', 5.3),\n",
    "    ('AAATAA', 9.1),\n",
    "    ('AAAAAG', 9.4),\n",
    "    ('TTAGCT', 3.2),\n",
    "    ('CAAAAA', 9.9),\n",
    "    ('ACAAAA', 9.8),\n",
    "    ('AAAACA', 9.8),\n",
    "    ('CCAATA', 7.8),\n",
    "    ('CCCGCC', 6.8),\n",
    "    ('CGGATC', 6.6),\n",
    "    ('CACGCC', 6.9),\n",
    "    ('AGGACG', 6.5),\n",
    "    ('CGTGCG', 4.9),\n",
    "    ('GGGGGA', 4.3),\n",
    "    ('GCCGGA', 4.5),\n",
    "    ('TGGTGA', 3.5),\n",
    "    ('CGGTTA', 3.8),\n",
    "    ('TTGTGA', 2.5),\n",
    "    ('TTTTTG', 1.1),\n",
    "    ('TAATAA', 5.6),\n",
    "    ('GAGTGC', 5.0),\n",
    "    ('AAATAC', 8.7),\n",
    "    ('AACAAA', 9.9),\n",
    "    ('TTCTTT', 1.3),\n",
    "    ('TTTCTT', 1.2),\n",
    "    ('TTTTGT', 1.1),\n",
    "    ('GTTTTT', 1.1),\n",
    "    ('AACAAA', 9.8),\n",
    "    ('AAAAGA', 9.7),\n",
    "    ('TAAAAA', 9.4),\n",
    "]\n",
    "df = pd.DataFrame(data, columns = ['seq','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oh'] = df['seq'].apply(lambda x: one_hot_encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CGGACC', 6.8,\n",
       "       array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0.])], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 41, 32, 18, 26, 15, 24, 40, 6, 22, 3, 38, 42, 16, 35, 28, 5, 14, 8, 9, 25, 12, 43, 19, 4, 39, 1, 11, 23, 7, 34, 20, 37, 33, 44, 10, 17, 31, 29, 13, 0, 45, 30, 27, 2, 36]\n",
      "Train #: 36\n",
      "Test #: 10\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "idxs = list(range(df.shape[0]))\n",
    "random.shuffle(idxs)\n",
    "print(idxs)\n",
    "\n",
    "split = int(len(idxs)*0.8)\n",
    "train_idxs = idxs[:split]\n",
    "test_idxs = idxs[split:]\n",
    "\n",
    "print(\"Train #:\", len(train_idxs))\n",
    "print(\"Test #:\", len(test_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.index.isin(train_idxs)]\n",
    "test_df = df[df.index.isin(test_idxs)]\n",
    "\n",
    "x_train = torch.tensor(list(train_df['oh'].values))\n",
    "y_train = torch.tensor(list(train_df['score'].values)).unsqueeze(1)\n",
    "x_test  = torch.tensor(list(test_df['oh'].values))\n",
    "y_test  = torch.tensor(list(test_df['score'].values)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000],\n",
       "        [ 9.8000],\n",
       "        [ 2.0000],\n",
       "        [ 9.1000],\n",
       "        [ 6.5000],\n",
       "        [ 4.3000],\n",
       "        [ 4.5000],\n",
       "        [ 3.5000],\n",
       "        [ 5.0000],\n",
       "        [ 9.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30aa9617c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[15].reshape((6, 4)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[5.6000],\n",
      "        [4.1000],\n",
      "        [6.8000],\n",
      "        [2.5000]], dtype=torch.float64)\n",
      "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[3.4000],\n",
      "        [6.6000],\n",
      "        [4.0000],\n",
      "        [5.1000]], dtype=torch.float64)\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[9.0000],\n",
      "        [9.9000],\n",
      "        [1.0000],\n",
      "        [5.3000]], dtype=torch.float64)\n",
      "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 1., 0.]], dtype=torch.float64)\n",
      "tensor([[7.8000],\n",
      "        [3.0000],\n",
      "        [1.3000],\n",
      "        [4.9000]], dtype=torch.float64)\n",
      "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[6.8000],\n",
      "        [5.0000],\n",
      "        [1.1000],\n",
      "        [6.9000]], dtype=torch.float64)\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[9.9000],\n",
      "        [3.2000],\n",
      "        [9.8000],\n",
      "        [9.8000]], dtype=torch.float64)\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[9.7000],\n",
      "        [1.1000],\n",
      "        [7.0000],\n",
      "        [3.8000]], dtype=torch.float64)\n",
      "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[6.2000],\n",
      "        [8.0000],\n",
      "        [6.7000],\n",
      "        [9.8000]], dtype=torch.float64)\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[9.4000],\n",
      "        [1.1000],\n",
      "        [1.2000],\n",
      "        [8.7000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNA_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(24, 1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # lin wraps up the weights/bias dot product from before\n",
    "        return self.lin(xb)\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "model = DNA_Logistic()\n",
    "loss_func = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb.float()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = y_train[:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58.2392, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(preds,yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb.float()), yb.float())\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    #print(\"lb returning:\",loss.item(), len(xb))\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, test_dl):\n",
    "    train_losses = []    \n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"TRAIN\")\n",
    "        model.train()\n",
    "        ts = []\n",
    "        ns = []\n",
    "        for xb, yb in train_dl:\n",
    "            t, n = loss_batch(model, loss_func, xb, yb, opt)\n",
    "            ts.append(t)\n",
    "            ns.append(n)\n",
    "        train_loss = np.sum(np.multiply(ts, ns)) / np.sum(ns)\n",
    "        train_losses.append(train_loss)\n",
    "#         losses, nums = zip(\n",
    "#             # loop through test batches\n",
    "#             # returns loss calc for test set batch size\n",
    "#             # unzips into two lists\n",
    "#             *[loss_batch(model, loss_func, xb, yb) for xb, yb in train_dl]\n",
    "#         )\n",
    "#         print(\"losses\", losses)\n",
    "#         print(\"nums\", nums)\n",
    "#         train_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "#         train_losses.append(train_loss)\n",
    "#         print(epoch, train_loss)\n",
    "        \n",
    "        print(\"EVAL\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                # loop through test batches\n",
    "                # returns loss calc for test set batch size\n",
    "                # unzips into two lists\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in test_dl]\n",
    "            )\n",
    "        # Gets average MSE loss across all batches (may be of diff sizes, hence the multiply)\n",
    "        print(\"losses\", losses)\n",
    "        print(\"nums\", nums)\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "EVAL\n",
      "losses (18.75469398498535, 21.69134521484375)\n",
      "nums (8, 2)\n",
      "0 19.34202423095703\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (8.681900024414062, 10.339454650878906)\n",
      "nums (8, 2)\n",
      "1 9.013410949707032\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (4.36370849609375, 5.328217029571533)\n",
      "nums (8, 2)\n",
      "2 4.556610202789306\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (2.430368661880493, 3.0053441524505615)\n",
      "nums (8, 2)\n",
      "3 2.545363759994507\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (1.4986082315444946, 1.866747260093689)\n",
      "nums (8, 2)\n",
      "4 1.5722360372543336\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (1.0193586349487305, 1.2771519422531128)\n",
      "nums (8, 2)\n",
      "5 1.070917296409607\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.75172358751297, 0.9639832377433777)\n",
      "nums (8, 2)\n",
      "6 0.7941755175590515\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.5846325159072876, 0.7489259243011475)\n",
      "nums (8, 2)\n",
      "7 0.6174911975860595\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.48167771100997925, 0.6272326707839966)\n",
      "nums (8, 2)\n",
      "8 0.5107887029647827\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.4165768027305603, 0.538201630115509)\n",
      "nums (8, 2)\n",
      "9 0.44090176820755006\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3754390776157379, 0.4750153124332428)\n",
      "nums (8, 2)\n",
      "10 0.3953543245792389\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.346606582403183, 0.45048707723617554)\n",
      "nums (8, 2)\n",
      "11 0.36738268136978147\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3304527699947357, 0.4165118932723999)\n",
      "nums (8, 2)\n",
      "12 0.34766459465026855\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3219306468963623, 0.38905689120292664)\n",
      "nums (8, 2)\n",
      "13 0.33535589575767516\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.31445226073265076, 0.3817177414894104)\n",
      "nums (8, 2)\n",
      "14 0.3279053568840027\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3130849599838257, 0.3680286705493927)\n",
      "nums (8, 2)\n",
      "15 0.3240737020969391\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.31178349256515503, 0.3682853579521179)\n",
      "nums (8, 2)\n",
      "16 0.3230838656425476\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3141442537307739, 0.36191892623901367)\n",
      "nums (8, 2)\n",
      "17 0.3236991882324219\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.31388968229293823, 0.36534127593040466)\n",
      "nums (8, 2)\n",
      "18 0.32418000102043154\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.31817781925201416, 0.3568459153175354)\n",
      "nums (8, 2)\n",
      "19 0.3259114384651184\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3201292157173157, 0.3562915027141571)\n",
      "nums (8, 2)\n",
      "20 0.32736167311668396\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3238811194896698, 0.35265621542930603)\n",
      "nums (8, 2)\n",
      "21 0.32963613867759706\n",
      "TRAIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewilson6/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607369981906/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL\n",
      "losses (0.3253081738948822, 0.35731539130210876)\n",
      "nums (8, 2)\n",
      "22 0.33170961737632754\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3260495960712433, 0.3666001856327057)\n",
      "nums (8, 2)\n",
      "23 0.3341597139835358\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3283992409706116, 0.36898162961006165)\n",
      "nums (8, 2)\n",
      "24 0.3365157186985016\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3311214745044708, 0.3722897171974182)\n",
      "nums (8, 2)\n",
      "25 0.3393551230430603\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.33198291063308716, 0.38056325912475586)\n",
      "nums (8, 2)\n",
      "26 0.3416989803314209\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3341617286205292, 0.38324177265167236)\n",
      "nums (8, 2)\n",
      "27 0.3439777374267578\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.336866557598114, 0.38448822498321533)\n",
      "nums (8, 2)\n",
      "28 0.34639089107513427\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3380714952945709, 0.3891933560371399)\n",
      "nums (8, 2)\n",
      "29 0.3482958674430847\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34051546454429626, 0.3935700058937073)\n",
      "nums (8, 2)\n",
      "30 0.35112637281417847\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3405519723892212, 0.40309929847717285)\n",
      "nums (8, 2)\n",
      "31 0.3530614376068115\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3406568765640259, 0.41461947560310364)\n",
      "nums (8, 2)\n",
      "32 0.3554493963718414\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34113824367523193, 0.4223041534423828)\n",
      "nums (8, 2)\n",
      "33 0.3573714256286621\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34186097979545593, 0.4270241856575012)\n",
      "nums (8, 2)\n",
      "34 0.358893620967865\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34415170550346375, 0.42924070358276367)\n",
      "nums (8, 2)\n",
      "35 0.3611695051193237\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34438356757164, 0.43698281049728394)\n",
      "nums (8, 2)\n",
      "36 0.3629034161567688\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3447408676147461, 0.4417485296726227)\n",
      "nums (8, 2)\n",
      "37 0.3641424000263214\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3449837863445282, 0.4498645067214966)\n",
      "nums (8, 2)\n",
      "38 0.36595993041992186\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3466334939002991, 0.4526560306549072)\n",
      "nums (8, 2)\n",
      "39 0.3678380012512207\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3474162518978119, 0.45613259077072144)\n",
      "nums (8, 2)\n",
      "40 0.3691595196723938\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.34873276948928833, 0.45990750193595886)\n",
      "nums (8, 2)\n",
      "41 0.37096771597862244\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.35066694021224976, 0.4596168100833893)\n",
      "nums (8, 2)\n",
      "42 0.37245691418647764\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3519645929336548, 0.4622037708759308)\n",
      "nums (8, 2)\n",
      "43 0.37401242852211\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.35164517164230347, 0.468010812997818)\n",
      "nums (8, 2)\n",
      "44 0.37491829991340636\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.35290199518203735, 0.4721055030822754)\n",
      "nums (8, 2)\n",
      "45 0.37674269676208494\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3528501093387604, 0.47997936606407166)\n",
      "nums (8, 2)\n",
      "46 0.37827596068382263\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3530502915382385, 0.4850040078163147)\n",
      "nums (8, 2)\n",
      "47 0.37944103479385377\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.35347118973731995, 0.48887673020362854)\n",
      "nums (8, 2)\n",
      "48 0.38055229783058164\n",
      "TRAIN\n",
      "EVAL\n",
      "losses (0.3535018265247345, 0.49536263942718506)\n",
      "nums (8, 2)\n",
      "49 0.38187398910522463\n"
     ]
    }
   ],
   "source": [
    "tl, vl = fit(50, model, loss_func, optimizer, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9786], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor(one_hot_encode(\"TGTAAT\"))\n",
    "model(s.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f30aa829bb0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vl)\n",
    "plt.plot(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAA tensor([10.3558], grad_fn=<AddBackward0>)\n",
      "CCCCCC tensor([6.5585], grad_fn=<AddBackward0>)\n",
      "GGGGGG tensor([4.0165], grad_fn=<AddBackward0>)\n",
      "TTTTTT tensor([0.6569], grad_fn=<AddBackward0>)\n",
      "AACCAA tensor([8.3212], grad_fn=<AddBackward0>)\n",
      "CCGGGG tensor([5.1607], grad_fn=<AddBackward0>)\n",
      "GGGTAA tensor([5.0042], grad_fn=<AddBackward0>)\n",
      "TTTCGT tensor([1.8137], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for dna in ['AAAAAA', 'CCCCCC','GGGGGG','TTTTTT','AACCAA','CCGGGG','GGGTAA', 'TTTCGT']:\n",
    "    s = torch.tensor(one_hot_encode(dna))\n",
    "    pred = model(s.float())\n",
    "    print(dna, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
