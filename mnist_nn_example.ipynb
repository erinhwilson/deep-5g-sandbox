{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAANgUlEQVR4nO3db6xUdX7H8c+nyMYE1ggl6o2LuhCjbUiEhmgTSaUYNtQnSKINPKg23eTugzWuprHFbcya3GxC2m5rYuKau9EAzSIhka2yVnfNdVPbxGy8AgqCq5RQloVwgzzgrkYR+PbBPTRXvPOby/w7A9/3K5nMzPnOmfnmcD+cM+fP/BwRAnD5+4O6GwDQG4QdSIKwA0kQdiAJwg4kcUUvP8w2u/6BLosITzW9rTW77VW2f2P7gO317bwXgO5yq8fZbc+Q9KGklZKOSHpb0rqI2FeYhzU70GXdWLPfLulARByMiNOStkpa3cb7AeiidsJ+vaTfTnp+pJr2JbYHbY/aHm3jswC0qZ0ddFNtKnxlMz0ihiUNS2zGA3VqZ81+RNL8Sc+/Ieloe+0A6JZ2wv62pJttf9P21yStlfRyZ9oC0Gktb8ZHxBnbD0n6haQZkp6PiPc71hmAjmr50FtLH8Z3dqDrunJSDYBLB2EHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfR0yGa0Zvbs2cX6okWLGtbuu+++4rynTp0q1pcsWVKsDwwMFOvPPvtsw9rmzZuL8547d65Yx8VhzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTCKaw8sXLiwWB8aGirWV61aVaxfffXVDWufffZZcd4zZ84U67NmzSrWP//882L9yiuvbFhbuXJlcd6RkZFiHVNrNIprWyfV2D4kaVzSWUlnImJpO+8HoHs6cQbdn0fEiQ68D4Au4js7kES7YQ9Jv7T9ju3BqV5ge9D2qO3RNj8LQBva3Yy/MyKO2r5G0uu2P4iINye/ICKGJQ1LeXfQAf2grTV7RByt7sck/UzS7Z1oCkDntRx227Nsf/38Y0nfkrS3U40B6KyWj7PbXqCJtbk08XVgS0T8sMk8KTfjX3vttWK92XXbBw4cKNY//vjjhrW33nqrOO8HH3xQrF911VXFerPj+Dt27Gj5s9esWVOsY2odP84eEQcl3dZyRwB6ikNvQBKEHUiCsANJEHYgCcIOJMElrj1www03FOuHDx/uUSe9t2vXroa1W265pTjvddddV6w3+xnsrBodemPNDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMGRzD1zOx9HvuOOOYr00nPT27duL846Pj7fUE6bGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB6dhQ1G7J5dLQ8qtecOXMa1krH4CXpxAnGC20F17MDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcz57cvHnzivVt27YV6wsXLizWV6xY0bDGcfTearpmt/287THbeydNm2v7ddsfVfeNz5wA0Bemsxm/UdKqC6atlzQSETdLGqmeA+hjTcMeEW9KOnnB5NWSNlWPN0m6t7NtAei0Vr+zXxsRxyQpIo7ZvqbRC20PShps8XMAdEjXd9BFxLCkYYkLYYA6tXro7bjtAUmq7sc61xKAbmg17C9LerB6/KCklzrTDoBuaXo9u+0XJC2XNE/ScUk/kPTvkrZJukHSYUn3R8SFO/Gmei8247ugNI75Aw88UJx37dq1xfrixYuL9dOnTxfrzzzzTMPawYMHi/Nu2bKlWD95sumfXEqNrmdv+p09ItY1KN3dVkcAeorTZYEkCDuQBGEHkiDsQBKEHUiCn5K+BNx1113F+saNGxvWbrzxxg530zt79uwp1m+77bYedXJp4aekgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJfkr6EvDJJ58U67t27WpY27x5c3HeZpeZvvRS936qYN26RhdUTnjqqaeK9SeeeKJYHxoautiWLmus2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa5nR9/asWNHsb5s2bJifc6cnIMLcz07kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ezoW88991yx3uw4O76s6Zrd9vO2x2zvnTTtSdu/s727ut3T3TYBtGs6m/EbJa2aYvq/RsTi6vYfnW0LQKc1DXtEvCnpZA96AdBF7eyge8j2e9VmfsOTkG0P2h61PdrGZwFoU6th/7GkhZIWSzom6UeNXhgRwxGxNCKWtvhZADqgpbBHxPGIOBsR5yT9RNLtnW0LQKe1FHbbA5OerpG0t9FrAfSHpsfZbb8gabmkebaPSPqBpOW2F0sKSYckfad7LQJTu+KK8p/vvHnzGtZOnDjR6Xb6XtOwR8RUv+RfPtsBQN/hdFkgCcIOJEHYgSQIO5AEYQeS4BJX9K3SoTNJOnPmTLGe8fBaCWt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCIZvRt8bGxor1mTNnFusM2fxlrNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmuZ++AZj9pvGHDhmL98ccfL9a/+OKLi+6pX8yYMaNh7emnny7O2+x69qGhoZZ6yoo1O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXsHbB8+fJi/Y033ijWX3311WL90UcfLdY//PDDYr2bFixYUKwPDw83rK1YsaI47549e4r1u+++u1jP+rvxLV/Pbnu+7V/Z3m/7fdvfq6bPtf267Y+q+5y/FABcIqazGX9G0t9GxB9J+lNJ37X9x5LWSxqJiJsljVTPAfSppmGPiGMRsbN6PC5pv6TrJa2WtKl62SZJ93apRwAdcFHnxtu+SdISSb+WdG1EHJMm/kOwfU2DeQYlDbbZJ4A2TTvstmdLelHSIxFxyp5yH8BXRMSwpOHqPS7LHXTApWBah95sz9RE0H8aEdurycdtD1T1AUnlnwIFUKumh948sQrfJOlkRDwyafo/Sfo4IjbYXi9pbkT8XZP3uizX7LNnzy7W9+3bV6zPnz+/WD906FCxXrpEttnhp2XLlhXrzXq7//77i/XSsnn33XeL865atapYP378eLGeVaNDb9PZjL9T0l9J2mN7dzXt+5I2SNpm+9uSDksq/6sDqFXTsEfEf0tq9AW9fFYDgL7B6bJAEoQdSIKwA0kQdiAJwg4kwSWuPbBo0aJifcuWLW3N303NzpRs9vczMjLSsPbYY48V5929e3exjqkxZDOQHGEHkiDsQBKEHUiCsANJEHYgCcIOJMFx9j5w6623Fuvr1q0r1h9++OGGtU8//bQ4786dO4v1rVu3FuuvvPJKsT4+Pt6wdvbs2eK8aA3H2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgCY6zA5cZjrMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJNw257vu1f2d5v+33b36umP2n7d7Z3V7d7ut8ugFY1PanG9oCkgYjYafvrkt6RdK+kv5T0+4j452l/GCfVAF3X6KSa6YzPfkzSserxuO39kq7vbHsAuu2ivrPbvknSEkm/riY9ZPs928/bntNgnkHbo7ZH22sVQDumfW687dmS/lPSDyNiu+1rJZ2QFJKGNLGp/zdN3oPNeKDLGm3GTyvstmdK+rmkX0TEv0xRv0nSzyOiOAIhYQe6r+ULYTwxjOdzkvZPDnq14+68NZL2ttskgO6Zzt74ZZL+S9IeSeeqyd+XtE7SYk1sxh+S9J1qZ17pvVizA13W1mZ8pxB2oPu4nh1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BE0x+c7LATkv530vN51bR+1K+99WtfEr21qpO93dio0NPr2b/y4fZoRCytrYGCfu2tX/uS6K1VveqNzXggCcIOJFF32Idr/vySfu2tX/uS6K1VPemt1u/sAHqn7jU7gB4h7EAStYTd9irbv7F9wPb6OnpoxPYh23uqYahrHZ+uGkNvzPbeSdPm2n7d9kfV/ZRj7NXUW18M410YZrzWZVf38Oc9/85ue4akDyWtlHRE0tuS1kXEvp420oDtQ5KWRkTtJ2DY/jNJv5e0+fzQWrb/UdLJiNhQ/Uc5JyL+vk96e1IXOYx3l3prNMz4X6vGZdfJ4c9bUcea/XZJByLiYESclrRV0uoa+uh7EfGmpJMXTF4taVP1eJMm/lh6rkFvfSEijkXEzurxuKTzw4zXuuwKffVEHWG/XtJvJz0/ov4a7z0k/dL2O7YH625mCteeH2arur+m5n4u1HQY7166YJjxvll2rQx/3q46wj7V0DT9dPzvzoj4E0l/Iem71eYqpufHkhZqYgzAY5J+VGcz1TDjL0p6JCJO1dnLZFP01ZPlVkfYj0iaP+n5NyQdraGPKUXE0ep+TNLPNPG1o58cPz+CbnU/VnM//y8ijkfE2Yg4J+knqnHZVcOMvyjppxGxvZpc+7Kbqq9eLbc6wv62pJttf9P21yStlfRyDX18he1Z1Y4T2Z4l6Vvqv6GoX5b0YPX4QUkv1djLl/TLMN6NhhlXzcuu9uHPI6LnN0n3aGKP/P9I+oc6emjQ1wJJ71a39+vuTdILmtis+0ITW0TflvSHkkYkfVTdz+2j3v5NE0N7v6eJYA3U1NsyTXw1fE/S7up2T93LrtBXT5Ybp8sCSXAGHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8X+1gG2Xqe8fAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[50].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4096)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    # @ = dot product\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2,3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2],[3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[3, 4]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4925, -2.0708, -3.3481, -2.9486, -1.9830, -2.2611, -2.0306, -2.3089,\n",
      "        -2.0453, -2.2849], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb)  # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3156, -2.7476, -2.3398, -2.2731, -2.4189, -2.6368, -2.4201, -1.9261,\n",
       "        -1.9033, -2.3692], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    # negative log likelihood\n",
    "    # input = preds, target = actual labels\n",
    "    # range 0,64\n",
    "    # target val gives index into tensor\n",
    "    # take mean of all preds?\n",
    "    # preds already given in log of softmax likelihood, so just take negative\n",
    "    # and average\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4629, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4629, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-preds[range(0,64),yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4925, 2.0708, 3.3481, 2.9486, 1.9830, 2.2611, 2.0306, 2.3089, 2.0453,\n",
       "         2.2849],\n",
       "        [2.7040, 2.0292, 2.8860, 3.0940, 2.1691, 2.3970, 2.3477, 1.8913, 2.2260,\n",
       "         1.9604],\n",
       "        [2.3156, 2.7476, 2.3398, 2.2731, 2.4189, 2.6368, 2.4201, 1.9261, 1.9033,\n",
       "         2.3692],\n",
       "        [1.9397, 2.3239, 2.4062, 2.7792, 2.0980, 2.3475, 1.9272, 2.7014, 2.8125,\n",
       "         2.1621],\n",
       "        [2.6435, 2.2995, 2.5444, 2.9766, 1.8239, 2.4556, 2.1911, 2.1855, 1.7389,\n",
       "         2.9573],\n",
       "        [2.4268, 2.1632, 2.6023, 3.0094, 1.6068, 2.2377, 2.6596, 2.0795, 2.6057,\n",
       "         2.3305],\n",
       "        [2.2999, 2.4298, 2.3042, 2.9261, 1.8385, 2.4994, 2.3556, 2.0991, 2.2210,\n",
       "         2.3954],\n",
       "        [2.2409, 2.4880, 2.8667, 2.7289, 1.8841, 2.3895, 2.1950, 2.0858, 2.1771,\n",
       "         2.3453],\n",
       "        [2.4238, 2.4460, 2.2053, 2.7470, 2.0259, 2.3630, 2.3145, 2.2451, 2.1481,\n",
       "         2.2733],\n",
       "        [2.6126, 2.2645, 2.5877, 2.9000, 2.1517, 2.6701, 2.4138, 2.0921, 1.6986,\n",
       "         2.1966],\n",
       "        [2.8221, 2.0593, 2.7837, 2.7704, 1.7946, 2.3763, 2.5686, 2.0367, 2.2869,\n",
       "         2.1140],\n",
       "        [2.4834, 2.2830, 2.1958, 2.6833, 1.9455, 2.2562, 2.1641, 2.2937, 2.4709,\n",
       "         2.4413],\n",
       "        [2.7847, 2.1269, 2.6661, 2.7681, 1.9010, 2.8403, 2.1188, 1.8086, 2.4221,\n",
       "         2.2433],\n",
       "        [2.7595, 2.2768, 2.6145, 3.1369, 2.1197, 2.5987, 2.5008, 1.4431, 2.3718,\n",
       "         2.1940],\n",
       "        [2.3942, 2.3432, 2.1844, 2.6929, 2.1010, 2.5774, 2.2191, 2.3392, 2.0983,\n",
       "         2.2403],\n",
       "        [3.0540, 1.9076, 2.4667, 3.0123, 1.6854, 2.9097, 2.3877, 2.4882, 1.6534,\n",
       "         2.7461],\n",
       "        [2.3121, 2.0556, 2.8336, 2.9795, 1.9193, 2.1307, 2.2467, 2.1066, 2.5330,\n",
       "         2.3965],\n",
       "        [2.5993, 2.2682, 2.2900, 3.2710, 1.7568, 2.1596, 2.5651, 2.5795, 1.9775,\n",
       "         2.2650],\n",
       "        [2.3394, 2.5128, 2.7718, 2.6926, 2.4458, 2.4488, 2.5032, 1.6378, 2.1386,\n",
       "         2.0777],\n",
       "        [3.0235, 2.0067, 2.5144, 2.8219, 1.8598, 2.2877, 2.5120, 2.5727, 1.7455,\n",
       "         2.4381],\n",
       "        [2.4173, 2.1341, 2.5644, 2.5795, 2.2429, 2.2843, 2.1927, 1.9769, 2.0866,\n",
       "         2.8562],\n",
       "        [2.7792, 1.9982, 2.7510, 3.2764, 2.3237, 2.5189, 2.3268, 1.8781, 2.5419,\n",
       "         1.6448],\n",
       "        [2.5826, 1.8886, 2.4251, 2.5329, 2.1339, 2.3662, 2.4190, 2.4476, 1.9852,\n",
       "         2.5234],\n",
       "        [1.9457, 2.3258, 2.3852, 2.6755, 2.0752, 2.3038, 1.9313, 2.6408, 2.8009,\n",
       "         2.3429],\n",
       "        [2.5657, 1.7858, 2.5497, 2.8726, 2.0936, 2.4804, 2.5310, 2.0157, 2.5604,\n",
       "         2.0893],\n",
       "        [2.0139, 2.5325, 2.7943, 3.4328, 2.1574, 2.0181, 2.4480, 1.7313, 2.4399,\n",
       "         2.3603],\n",
       "        [2.4451, 2.2070, 2.6668, 2.5039, 2.0774, 2.6394, 2.5175, 1.9764, 2.0047,\n",
       "         2.2885],\n",
       "        [2.7978, 2.2240, 3.0587, 2.6472, 1.8510, 2.3881, 2.0716, 2.0283, 2.4895,\n",
       "         2.0900],\n",
       "        [2.7688, 2.4529, 2.5284, 3.3561, 1.6075, 3.0791, 1.8031, 1.8453, 2.1582,\n",
       "         2.9591],\n",
       "        [2.5746, 1.9431, 2.4191, 2.4255, 1.7884, 2.8164, 2.4888, 2.1463, 2.5816,\n",
       "         2.2976],\n",
       "        [3.2488, 2.0119, 2.5055, 3.0625, 1.7480, 2.5094, 2.8041, 1.9146, 2.1533,\n",
       "         2.1241],\n",
       "        [2.6145, 2.3238, 2.3530, 2.9785, 1.7164, 1.9674, 2.3817, 2.6788, 2.4225,\n",
       "         2.1744],\n",
       "        [2.2884, 1.7660, 2.8823, 3.0849, 2.1687, 2.8655, 2.4545, 1.9009, 2.6192,\n",
       "         1.9219],\n",
       "        [3.0500, 1.9754, 2.2695, 2.8763, 1.7790, 2.3356, 2.3248, 2.7317, 1.9328,\n",
       "         2.5129],\n",
       "        [2.8905, 2.3662, 2.4696, 3.5172, 1.9567, 2.2340, 2.5081, 2.0959, 2.5563,\n",
       "         1.5802],\n",
       "        [2.5703, 1.9844, 2.1357, 2.6796, 2.3029, 2.3062, 2.3531, 2.3204, 2.4904,\n",
       "         2.0918],\n",
       "        [2.5421, 2.1839, 2.8635, 3.5244, 1.7846, 2.9970, 2.6253, 1.6480, 2.1932,\n",
       "         2.0562],\n",
       "        [2.8334, 2.1475, 2.8449, 3.5186, 2.0891, 1.9679, 2.3537, 1.7695, 2.4085,\n",
       "         2.1397],\n",
       "        [2.8384, 1.7344, 2.7033, 3.0994, 1.8028, 2.4610, 2.3664, 1.9045, 2.3955,\n",
       "         2.6753],\n",
       "        [2.7250, 1.8212, 2.6667, 3.2170, 2.1812, 2.8061, 2.5845, 1.6718, 2.1813,\n",
       "         2.1761],\n",
       "        [2.4502, 2.4153, 2.0789, 2.9123, 2.0205, 2.2742, 2.5520, 2.4010, 2.0072,\n",
       "         2.2389],\n",
       "        [2.2802, 2.5238, 2.5648, 3.2241, 1.7767, 2.1013, 2.6651, 2.2513, 2.1665,\n",
       "         2.1209],\n",
       "        [2.8164, 2.0838, 2.1238, 2.7276, 1.8440, 2.7387, 2.4896, 2.2926, 2.0254,\n",
       "         2.3855],\n",
       "        [2.6943, 2.0208, 2.6104, 2.6751, 2.0353, 2.3161, 2.3257, 2.5441, 1.8427,\n",
       "         2.3697],\n",
       "        [2.5210, 2.3095, 2.5346, 2.7869, 1.8814, 2.3370, 2.1542, 2.0537, 2.3437,\n",
       "         2.4059],\n",
       "        [2.8642, 2.3276, 2.5191, 3.0353, 1.5893, 2.5471, 2.4943, 2.2532, 1.7318,\n",
       "         2.6610],\n",
       "        [2.0505, 2.4333, 2.7162, 2.7861, 1.5639, 2.5359, 2.4533, 2.1631, 2.6251,\n",
       "         2.3657],\n",
       "        [2.4842, 2.3493, 2.5909, 2.9183, 2.3744, 2.4890, 2.5468, 2.2628, 1.5848,\n",
       "         2.0498],\n",
       "        [2.9392, 1.9242, 2.2252, 2.6217, 2.0893, 2.5265, 2.3075, 2.1284, 2.4392,\n",
       "         2.1992],\n",
       "        [2.4448, 2.2880, 2.9549, 2.7083, 1.9458, 2.1723, 2.3289, 2.2461, 2.1629,\n",
       "         2.1366],\n",
       "        [2.8820, 2.1808, 2.3389, 2.4407, 2.1201, 2.5708, 2.5102, 1.9349, 2.4210,\n",
       "         1.9917],\n",
       "        [2.5959, 2.2127, 2.6716, 2.9128, 2.1048, 2.8584, 1.8814, 1.9959, 2.6150,\n",
       "         1.8846],\n",
       "        [2.9133, 2.1437, 2.4655, 2.9782, 1.6535, 3.0179, 2.1934, 2.0556, 2.1835,\n",
       "         2.3010],\n",
       "        [2.9409, 1.8175, 2.3838, 2.9254, 2.0078, 2.6923, 2.2973, 2.2430, 2.2534,\n",
       "         2.0781],\n",
       "        [2.7400, 1.9996, 2.4890, 2.6992, 1.8939, 2.9199, 2.5195, 2.0092, 1.9783,\n",
       "         2.3809],\n",
       "        [2.3800, 2.4854, 2.2200, 2.4415, 1.6739, 2.9252, 2.7019, 2.5192, 1.9657,\n",
       "         2.3056],\n",
       "        [2.7531, 2.1160, 2.7809, 3.1344, 1.9156, 2.8736, 1.8052, 1.7386, 2.5905,\n",
       "         2.3936],\n",
       "        [2.8971, 2.0602, 2.5408, 2.8730, 1.8820, 2.5482, 2.4799, 2.4433, 1.6095,\n",
       "         2.5138],\n",
       "        [2.6231, 2.4522, 2.8003, 2.6736, 1.8985, 2.9038, 1.8871, 1.7390, 2.0378,\n",
       "         3.0078],\n",
       "        [2.0735, 2.4653, 2.3854, 2.8334, 2.0909, 2.2351, 2.0339, 2.5598, 2.7923,\n",
       "         1.9774],\n",
       "        [2.3815, 2.1163, 2.5710, 2.8508, 2.7300, 2.7826, 1.8056, 2.2123, 2.1624,\n",
       "         1.9886],\n",
       "        [2.2092, 2.2740, 2.5709, 2.6056, 2.0342, 2.7700, 2.0617, 2.0707, 2.2910,\n",
       "         2.4186],\n",
       "        [2.5516, 2.3879, 2.6938, 3.2428, 2.1449, 2.5383, 2.5074, 1.5560, 2.4014,\n",
       "         1.9351],\n",
       "        [3.2114, 1.7736, 2.8080, 3.3438, 1.8839, 2.3179, 1.9920, 2.2923, 2.6502,\n",
       "         1.9967]], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-preds[range(0,64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    # feed actual preds in as out\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0312)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewilson6/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607369981906/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs # batch starting place\n",
    "        end_i = start_i + bs # batch size from start\n",
    "        xb = x_train[start_i:end_i] # get examples and labels\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)# make predictions - multiply inputs @ weights + bias, log softmax\n",
    "        loss = loss_func(pred, yb) # nll of preds\n",
    "\n",
    "        loss.backward() # update gradients\n",
    "        with torch.no_grad(): # actually update values in weights/bias based on gradient and lr\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_() # reset gradients to 0 after update\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40 // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now using nn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    # redefine without softmax\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # same as \"model()\" from before\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4087, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    # training function\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): # auto update all parameters defined in MnistLogistic\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0807, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3508, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # lin wraps up the weights/bias dot product from before\n",
    "        return self.lin(xb)\n",
    "    \n",
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4161, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0805, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "# same as fit()\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        # instead of updating params, the optimizer just does that in Step\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0820, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([64, 784]) torch.Size([64])\n",
      "torch.Size([16, 784]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0811, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3281)\n",
      "1 tensor(0.2953)\n",
      "2 tensor(0.3267)\n",
      "3 tensor(0.2866)\n",
      "4 tensor(0.2672)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train() # sets training mode to True, doesn't actually train\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        # why multiply losses by len of batch?\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3085571125268936\n",
      "1 0.4064069236278534\n",
      "2 0.2768992762565613\n",
      "3 0.3202983641266823\n",
      "4 0.299762332046032\n",
      "5 0.2895145841956139\n",
      "6 0.341851800596714\n",
      "7 0.3360989359021187\n"
     ]
    }
   ],
   "source": [
    "# whole training process?\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(8, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3383253442287445\n",
      "1 0.22268746160268785\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3603972136259079\n",
      "1 0.21820324252843856\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.preprocess(x, y)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2402871753692627\n",
      "1 0.1963001360177994\n",
      "2 0.1785460590481758\n",
      "3 0.1790879687666893\n",
      "4 0.16472950867414474\n",
      "5 0.14510966917276383\n",
      "6 0.14869890780448913\n",
      "7 0.14343947072029115\n"
     ]
    }
   ],
   "source": [
    "fit(8, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
